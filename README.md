<h2>DC:Dual-Level Contrastive Learning for Improving Conciseness of Summarization</h2>

This repo is for our paper "Dual-Level Contrastive Learning for Improving Conciseness of Summarization". 

### Train

The training phase uses half-floating-point precision to accelerate the model training, the current code only realizes the training on a single GPU, does not realize the multi-card parallel training, the graphics card memory needs to meet more than 24GB.

1. pytorch version >=1.12
2. pip install -r requirements.txt
3. python run.py

### Evaluate

For ROUGE calculation, we use the standard ROUGE Perl package from in our paper.  We provide the evaluation script in `cal_rouge.py`. You can use to computer you summary ROUGE. The file format for calculating ROUGE is given in the result folder and you need to follow this format for input.

##### Example: evaluating the model as a generator on CNNDM

```
# calculate the ROUGE scores using ROUGE Perl Package
python new_cal_rouge.py --ref ./result/test/reference/ --hyp ./result/test/candidate/ -l
```

### Results

The results of our experiments are placed under the RESULTS file, where you can view the results generated by the model. The following are ROUGE scores calcualted by the standard ROUGE Perl package.

- CNNDM

  |               | ROUGE-1 | ROUGE-2 | ROUGE-L | VAR   |
  | ------------- | ------- | ------- | ------- | ----- |
  | BART          | 44.33   | 21.15   | 41.06   | 0.022 |
  | BRIO          | 47.78   | 23.55   | 44.56   | 0.02  |
  | LFPE          | 45.93   | 22.30   | 42.44   | 0.03  |
  | DC(Our model) | 47.82   | 23.59   | 44.63   | 0.017 |

- XSum

  |         | ROUGE-1 | ROUGE-2 | ROUGE-L | VAR    |
  | ------- | ------- | ------- | ------- | ------ |
  | BART    | 45.14   | 22.27   | 37.25   |        |
  | PEGASUS | 47.38   | 24.54   | 39.41   | 0.0054 |
  | BRIO    | 49.07   | 25.59   | 40.47   | 0.0049 |
  | DC      | 47.75   | 24.86   | 39.72   | 0.0052 |

  

#### Generate

We uploaded the model weights to Google Cloud Drive for your use, [CNNDM](https://drive.google.com/drive/folders/11aOU5Yla5H1NjwQD-n-BrOcs98OfiigX?usp=sharing) and  [XSum](https://drive.google.com/drive/folders/15wN3BuntilDZeKusZoWtfmauzezEHw8b?usp=sharing) weights files, You could load these checkpoints using `model.load_state_dict(torch.load(path_to_checkpoint))`.You can run the xsum_generate.py and cnndm_generate.py directly to generate the appropriate summaries.



